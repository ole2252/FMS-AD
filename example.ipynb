{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "import requests \n",
    "import pickle as pkl \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from scipy import stats\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "\n",
    "#models \n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier  \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from vecstack import stacking\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import Framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 1\n",
    "preprocess data\n",
    "'''\n",
    "\n",
    "# Prepare data\n",
    "# data = pd.read_csv(\"mts_june_10m_rh.csv\", dtype='float').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# X = data.drop(['cs'], axis=1)\n",
    "# Y = data['cs']\n",
    "\n",
    "data = pd.read_pickle(r'all_metrics_data_3h.pkl')\n",
    "# data = pd.read_pickle(r'all_metrics_data_12h.pkl')\n",
    "\n",
    "X = data.drop(['time', 'label', \"txn_fail_num\"], axis=1)\n",
    "Y = data.label\n",
    "\n",
    "# Preproces for PCA\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = scaler.fit_transform(X)\n",
    "\n",
    "# Create PCA\n",
    "pca = PCA(n_components = 0.95)\n",
    "pca_df = pca.fit_transform(scaled_df)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 2\n",
    "Define models\n",
    "'''\n",
    "\n",
    "dbscan_model = DBSCAN(eps=3, min_samples=2)\n",
    "isolation_forest_model = IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), \\\n",
    "                        max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "kmeans_model = KMeans(n_clusters=2)\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "rf_model = RandomForestClassifier(max_depth=10, random_state=5)\n",
    "\n",
    "all_models = [dbscan_model, isolation_forest_model, kmeans_model, knn_model, svm_model, rf_model]\n",
    "unsupervised_models = [dbscan_model, isolation_forest_model, kmeans_model]\n",
    "supervised_models = [knn_model, svm_model, rf_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 2\n",
    "Build the framework\n",
    "'''\n",
    "fmsad = Framework.FMSAD(X,Y, supervised_models, unsupervised_models)\n",
    "\n",
    "fmsad.correlation_analysis()\n",
    "\n",
    "selected_feature_names = fmsad.correlation_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 3\n",
    "Initiate data set variations\n",
    "This can be used to create other models later\n",
    "'''\n",
    "\n",
    "all_feature_X = X\n",
    "correlation_analysis_X = X[selected_feature_names]\n",
    "PCA_X = pca_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 4\n",
    "Fit weights for weighted model\n",
    "parameters: models for ensemble to optimize,\n",
    "            Weight range to optimize\n",
    "'''\n",
    "\n",
    "# Optimize Unsupervised model weights\n",
    "fmsad.optimize_voting_parameters(list(itertools.permutations([1,1,1]))) # Change weights to desired range\n",
    "\n",
    "\n",
    "\n",
    "# Optimize All model weights\n",
    "fmsad.optimize_all_voting_parameters(all_models, list(itertools.permutations([1,1,1,1,1,1]))) # Change weights to desired range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [IsolationForest]\n",
      "    fold  0:  [0.36697248]\n",
      "    fold  1:  [0.30275229]\n",
      "    fold  2:  [0.38532110]\n",
      "    fold  3:  [0.35779817]\n",
      "    ----\n",
      "    MEAN:     [0.35321101] + [0.03077158]\n",
      "    FULL:     [0.35321101]\n",
      "\n",
      "model  1:     [KMeans]\n",
      "    fold  0:  [0.57798165]\n",
      "    fold  1:  [0.39449541]\n",
      "    fold  2:  [0.49541284]\n",
      "    fold  3:  [0.41284404]\n",
      "    ----\n",
      "    MEAN:     [0.47018349] + [0.07292712]\n",
      "    FULL:     [0.47018349]\n",
      "\n",
      "[10:35:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.94495413]\n",
      "    fold  1:  [0.94495413]\n",
      "    fold  2:  [0.91743119]\n",
      "    fold  3:  [0.95412844]\n",
      "    ----\n",
      "    MEAN:     [0.94036697] + [0.01376147]\n",
      "    FULL:     [0.94036697]\n",
      "\n",
      "model  1:     [Pipeline]\n",
      "    fold  0:  [0.96330275]\n",
      "    fold  1:  [0.97247706]\n",
      "    fold  2:  [0.93577982]\n",
      "    fold  3:  [0.97247706]\n",
      "    ----\n",
      "    MEAN:     [0.96100917] + [0.01504000]\n",
      "    FULL:     [0.96100917]\n",
      "\n",
      "model  2:     [RandomForestClassifier]\n",
      "    fold  0:  [0.96330275]\n",
      "    fold  1:  [0.95412844]\n",
      "    fold  2:  [0.91743119]\n",
      "    fold  3:  [0.97247706]\n",
      "    ----\n",
      "    MEAN:     [0.95183486] + [0.02089549]\n",
      "    FULL:     [0.95183486]\n",
      "\n",
      "[10:35:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [5]\n",
      "\n",
      "model  0:     [IsolationForest]\n",
      "    fold  0:  [0.36697248]\n",
      "    fold  1:  [0.30275229]\n",
      "    fold  2:  [0.38532110]\n",
      "    fold  3:  [0.35779817]\n",
      "    ----\n",
      "    MEAN:     [0.35321101] + [0.03077158]\n",
      "    FULL:     [0.35321101]\n",
      "\n",
      "model  1:     [KMeans]\n",
      "    fold  0:  [0.42201835]\n",
      "    fold  1:  [0.39449541]\n",
      "    fold  2:  [0.49541284]\n",
      "    fold  3:  [0.41284404]\n",
      "    ----\n",
      "    MEAN:     [0.43119266] + [0.03837890]\n",
      "    FULL:     [0.43119266]\n",
      "\n",
      "model  2:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.94495413]\n",
      "    fold  1:  [0.94495413]\n",
      "    fold  2:  [0.91743119]\n",
      "    fold  3:  [0.95412844]\n",
      "    ----\n",
      "    MEAN:     [0.94036697] + [0.01376147]\n",
      "    FULL:     [0.94036697]\n",
      "\n",
      "model  3:     [Pipeline]\n",
      "    fold  0:  [0.96330275]\n",
      "    fold  1:  [0.97247706]\n",
      "    fold  2:  [0.93577982]\n",
      "    fold  3:  [0.97247706]\n",
      "    ----\n",
      "    MEAN:     [0.96100917] + [0.01504000]\n",
      "    FULL:     [0.96100917]\n",
      "\n",
      "model  4:     [RandomForestClassifier]\n",
      "    fold  0:  [0.96330275]\n",
      "    fold  1:  [0.95412844]\n",
      "    fold  2:  [0.91743119]\n",
      "    fold  3:  [0.97247706]\n",
      "    ----\n",
      "    MEAN:     [0.95183486] + [0.02089549]\n",
      "    FULL:     [0.95183486]\n",
      "\n",
      "[10:35:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>supervised stacking</td>\n",
       "      <td>0.979452</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>0.990242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all model stacking</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.971705</td>\n",
       "      <td>2.690768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(StandardScaler(), SVC(gamma='auto'))</td>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.964713</td>\n",
       "      <td>0.968236</td>\n",
       "      <td>0.966078</td>\n",
       "      <td>0.036561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>supervised weighted voting</td>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.964713</td>\n",
       "      <td>0.968236</td>\n",
       "      <td>0.966078</td>\n",
       "      <td>0.227069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>0.963699</td>\n",
       "      <td>0.962400</td>\n",
       "      <td>0.965111</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.173914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>supervised voting</td>\n",
       "      <td>0.963014</td>\n",
       "      <td>0.961252</td>\n",
       "      <td>0.965358</td>\n",
       "      <td>0.962652</td>\n",
       "      <td>0.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>all model weighted voting</td>\n",
       "      <td>0.956164</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>0.956002</td>\n",
       "      <td>0.955542</td>\n",
       "      <td>0.865067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.943151</td>\n",
       "      <td>0.941690</td>\n",
       "      <td>0.944074</td>\n",
       "      <td>0.942489</td>\n",
       "      <td>0.042231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all model voting</td>\n",
       "      <td>0.708219</td>\n",
       "      <td>0.743639</td>\n",
       "      <td>0.678506</td>\n",
       "      <td>0.673475</td>\n",
       "      <td>0.657184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unsupervised stacking</td>\n",
       "      <td>0.678082</td>\n",
       "      <td>0.788606</td>\n",
       "      <td>0.597766</td>\n",
       "      <td>0.562679</td>\n",
       "      <td>2.225617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KMeans(n_clusters=2)</td>\n",
       "      <td>0.552055</td>\n",
       "      <td>0.584593</td>\n",
       "      <td>0.574981</td>\n",
       "      <td>0.545691</td>\n",
       "      <td>0.094788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unsupervised weighted voting</td>\n",
       "      <td>0.552055</td>\n",
       "      <td>0.584593</td>\n",
       "      <td>0.574981</td>\n",
       "      <td>0.545691</td>\n",
       "      <td>0.607099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ExtraTreeRegressor(max_depth=8, max_features=...</td>\n",
       "      <td>0.628767</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.584623</td>\n",
       "      <td>0.542958</td>\n",
       "      <td>0.397499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unsupervised voting</td>\n",
       "      <td>0.628767</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.584623</td>\n",
       "      <td>0.542958</td>\n",
       "      <td>0.562706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DBSCAN(eps=3, min_samples=2)</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.280822</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.040433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  accuracy  precision  \\\n",
       "7                                 supervised stacking  0.979452   0.975410   \n",
       "8                                  all model stacking  0.972603   0.967742   \n",
       "4               (StandardScaler(), SVC(gamma='auto'))  0.966438   0.964713   \n",
       "13                         supervised weighted voting  0.966438   0.964713   \n",
       "5   (DecisionTreeClassifier(max_depth=10, max_feat...  0.963699   0.962400   \n",
       "10                                  supervised voting  0.963014   0.961252   \n",
       "14                          all model weighted voting  0.956164   0.955284   \n",
       "3                              KNeighborsClassifier()  0.943151   0.941690   \n",
       "11                                   all model voting  0.708219   0.743639   \n",
       "6                               unsupervised stacking  0.678082   0.788606   \n",
       "2                                KMeans(n_clusters=2)  0.552055   0.584593   \n",
       "12                       unsupervised weighted voting  0.552055   0.584593   \n",
       "1   (ExtraTreeRegressor(max_depth=8, max_features=...  0.628767   0.680628   \n",
       "9                                 unsupervised voting  0.628767   0.680628   \n",
       "0                        DBSCAN(eps=3, min_samples=2)  0.561644   0.280822   \n",
       "\n",
       "      recall  f1 score      time  \n",
       "7   0.982955  0.978724  0.990242  \n",
       "8   0.977273  0.971705  2.690768  \n",
       "4   0.968236  0.966078  0.036561  \n",
       "13  0.968236  0.966078  0.227069  \n",
       "5   0.965111  0.963284  0.173914  \n",
       "10  0.965358  0.962652  0.293000  \n",
       "14  0.956002  0.955542  0.865067  \n",
       "3   0.944074  0.942489  0.042231  \n",
       "11  0.678506  0.673475  0.657184  \n",
       "6   0.597766  0.562679  2.225617  \n",
       "2   0.574981  0.545691  0.094788  \n",
       "12  0.574981  0.545691  0.607099  \n",
       "1   0.584623  0.542958  0.397499  \n",
       "9   0.584623  0.542958  0.562706  \n",
       "0   0.500000  0.359649  0.040433  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 5\n",
    "Build the framework\n",
    "'''\n",
    "# Run framework on selected models\n",
    "fmsad.generate_models([[0,3,2],[0,3,2],[3,1,1,3,2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
