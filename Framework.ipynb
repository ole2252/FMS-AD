{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "import requests \n",
    "import pickle as pkl \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from scipy import stats\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "\n",
    "#models \n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier  \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from vecstack import stacking\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "# data = pd.read_csv(\"mts_june_10m_rh.csv\", dtype='float').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# X = data.drop(['cs'], axis=1)\n",
    "# Y = data['cs']\n",
    "\n",
    "data = pd.read_pickle(r'all_metrics_data_3h.pkl')\n",
    "# data = pd.read_pickle(r'all_metrics_data_12h.pkl')\n",
    "\n",
    "X = data.drop(['time', 'label', \"txn_fail_num\"], axis=1)\n",
    "Y = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preproces for PCA\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = scaler.fit_transform(X)\n",
    "\n",
    "# Create PCA\n",
    "pca = PCA(n_components = 0.95)\n",
    "pca_df = pca.fit_transform(scaled_df)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMSAD:\n",
    "    def __init__(self, X, Y, supervised_models, unsupervised_models):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.supervised_models =supervised_models\n",
    "        self.unsupervised_models =unsupervised_models\n",
    "        self.all_models = unsupervised_models+supervised_models\n",
    "    \n",
    "    def correlation_analysis(self, plot_heatmap=False):\n",
    "        '''Calculate label correlation with respect to output label'''\n",
    "        correlation_txn_falure = {}\n",
    "\n",
    "        for label in self.X.columns:\n",
    "            r,p = stats.pearsonr(self.X[label],self.Y)\n",
    "            correlation_txn_falure[label] = (r,p)\n",
    "            \n",
    "            txn_falure_correlation = pd.DataFrame.from_dict(correlation_txn_falure, orient='index').rename(columns={0:'r', 1:'p-value'}).sort_values('r', ascending=False)\n",
    "        \n",
    "        if plot_heatmap:\n",
    "            plt.figure(figsize=(10,6))\n",
    "            sns.heatmap(txn_falure_correlation, cmap='GnBu', square=True, annot=True, linewidths=.5)\n",
    "            \n",
    "        df_index = list(txn_falure_correlation.index)\n",
    "\n",
    "        txn_falure_correlation = txn_falure_correlation.dropna(axis='rows')\n",
    "        return txn_falure_correlation\n",
    "    \n",
    "    def correlation_features(self, r_lim=0.5, p_lim=0.05):\n",
    "        '''Select features based specified boundaries'''\n",
    "        txn_falure_correlation = self.correlation_analysis()\n",
    "        selected_features = txn_falure_correlation[np.abs(txn_falure_correlation.r) >= r_lim]\n",
    "        selected_features = selected_features[selected_features['p-value'] <= p_lim]\n",
    "\n",
    "        selected_features_names = selected_features.index\n",
    "        return selected_features_names\n",
    "    \n",
    "    def evaluate(self, y_real, y_pred):\n",
    "        from sklearn import metrics\n",
    "        accuracy = accuracy_score(y_real,y_pred)\n",
    "        precision = precision_score(y_real, y_pred, average='macro')\n",
    "        recall = metrics.recall_score(y_real, y_pred, average='macro')\n",
    "        f1_score = metrics.f1_score(y_real, y_pred, average='macro') \n",
    "\n",
    "        # AUC curve\n",
    "        fpr, tpr, threshold = metrics.roc_curve(y_real, y_pred)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        return accuracy, precision, recall, f1_score, fpr, tpr, roc_auc\n",
    "\n",
    "    # since boolean predictions may be wrong way around\n",
    "    def result(self, y_real, y_pred):\n",
    "        from sklearn import metrics\n",
    "        if  metrics.f1_score(y_real, y_pred, average='macro') >  metrics.f1_score(y_real, [not y for y in y_pred], average='macro'):\n",
    "            return self.evaluate(y_real, y_pred)\n",
    "        else:\n",
    "            return self.evaluate(y_real, [not y for y in y_pred])\n",
    "\n",
    "    def show_res(self, res):\n",
    "        accuracy, precision, recall, f1_score, time = res\n",
    "        print(\"Accuracy\", accuracy)\n",
    "        print(\"Precision\", precision)\n",
    "        print(\"Recall\", recall)\n",
    "        print(\"F1 Score\", f1_score)\n",
    "        print(\"Time\", time)\n",
    "\n",
    "    def flip_if_inverted(self, Y_pred):\n",
    "        Y_pred = np.array([0 if i != 1 else 1 for i in Y_pred ])\n",
    "        if len(Y_pred[Y_pred == 1]) < len(Y_pred[Y_pred == 0]):\n",
    "\n",
    "            return [not elem for elem in Y_pred]\n",
    "        else:\n",
    "            return Y_pred\n",
    "\n",
    "    def validate_model(self, model,undersample=False, oversample=False, flip=True):\n",
    "        accuracy_, precision_, recall_, f1_score_,fpr_, tpr_, roc_auc_, time_ = [],[],[],[],[], [],[],[]\n",
    "\n",
    "        shuffle_split = StratifiedShuffleSplit(n_splits=5, test_size=0.4, random_state=0)\n",
    "        for train_index, test_index in shuffle_split.split(self.X,self.Y):\n",
    "            start_time = time.time()\n",
    "\n",
    "            if type(X) == pd.DataFrame:\n",
    "                X_train, X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
    "                Y_train, Y_test = self.Y.iloc[train_index], self.Y.iloc[test_index]\n",
    "            else:\n",
    "                X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "                Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n",
    "            if undersample:\n",
    "                undersampling = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "                X_train, Y_train = undersampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "            if oversample:\n",
    "                oversampling = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "                X_train, Y_train = oversampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "            fitted_model = model.fit(X_train, Y_train)\n",
    "            try:\n",
    "                y_pred = fitted_model.predict(X_test)\n",
    "            except:\n",
    "                y_pred = fitted_model.fit_predict(X_test)\n",
    "\n",
    "            if flip:\n",
    "                y_pred = self.flip_if_inverted(y_pred)\n",
    "\n",
    "            accuracy, precision, recall, f1_score, fpr, tpr, roc_auc = self.result(Y_test, y_pred)\n",
    "\n",
    "            end_time = time.time()\n",
    "            fpr_.append(fpr)\n",
    "            tpr_.append(tpr)\n",
    "\n",
    "            accuracy_.append(accuracy)\n",
    "            precision_.append(precision)\n",
    "            recall_.append(recall)\n",
    "            f1_score_.append(f1_score)\n",
    "            roc_auc_.append(roc_auc)\n",
    "            time_.append(end_time - start_time)              \n",
    "        return np.mean(accuracy_), np.mean(precision_), np.mean(recall_), np.mean(f1_score_), np.mean(time_)\n",
    "\n",
    "    def optimize_voting_parameters(self, w1, w2,w3):\n",
    "        tuning_res = pd.DataFrame(columns = [\"w1\", \"w2\", 'w3', \"accuracy\", \"precision\", \"recall\",\\\n",
    "                                             \"f1_score\", \"fpr\", \"tpr\", \"roc_auc\", \"time\"])\n",
    "\n",
    "        for w1_, w2_, w3_ in itertools.product(*[w1, w2,w3]):\n",
    "            dbscan_clf = DBSCAN(eps=3, min_samples=2)\n",
    "            if_clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), \\\n",
    "                                    max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "            kmeans_clf = KMeans(n_clusters=2)\n",
    "            KNN_clf = KNeighborsClassifier(n_neighbors=2)\n",
    "            svm_clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "            rf_clf = RandomForestClassifier(max_depth=10, random_state=5)      \n",
    "\n",
    "            # dbscan, IF and kmeans does not work since it is no classifier\n",
    "            model = VotingClassifier(estimators=[\n",
    "                    ('knn', KNN_clf), \\\n",
    "                    ('svm', svm_clf),('random forest', rf_clf)], voting='hard', weights=[w1_, w2_, w3_])\n",
    "            self.validate_model(model)\n",
    "\n",
    "            accuracy, precision, recall, f1_score, fpr, tpr, roc_auc, time = \\\n",
    "                    self.validate_model(model)\n",
    "\n",
    "            row = {\"w1\":w1_, \"w2\":w2_, 'w3':w3_,\"accuracy\":accuracy, \"precision\":precision,\\\n",
    "                   \"recall\":recall, \"f1_score\":f1_score, \"fpr\":fpr, \"tpr\":tpr, \"roc_auc\":roc_auc}\n",
    "            tuning_res = tuning_res.append(row, ignore_index=True)\n",
    "        return tuning_res.sort_values(\"f1_score\", ascending=False)\n",
    "    \n",
    "    \n",
    "    def weighted_vote_ensamble(self, models, weights=[1,1,1,1,1,1], undersample=False, oversample=False):\n",
    "        accuracy_, precision_, recall_, f1_score_,fpr_, tpr_, roc_auc_, time_ = [],[],[],[],[], [],[],[]\n",
    "\n",
    "        shuffle_split = StratifiedShuffleSplit(n_splits=5, test_size=0.4, random_state=0)\n",
    "        for train_index, test_index in shuffle_split.split(self.X,self.Y):\n",
    "            start_time = time.time()\n",
    "\n",
    "            if type(X) == pd.DataFrame:\n",
    "                X_train, X_test = self.X.iloc[train_index],self.X.iloc[test_index]\n",
    "                Y_train, Y_test = self.Y.iloc[train_index], self.Y.iloc[test_index]\n",
    "            else:\n",
    "                X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "                Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n",
    "            if undersample:\n",
    "                undersampling = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "                X_train, Y_train = undersampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "            if oversample:\n",
    "                oversampling = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "                X_train, Y_train = oversampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            results = []\n",
    "            for model, weight in zip(models, weights):\n",
    "                try:\n",
    "                    model.fit(X_train, Y_train)\n",
    "                    for i in range(weight):\n",
    "                        res = model.predict(X_test)\n",
    "                        res = self.flip_if_inverted(res)\n",
    "                        results.append(res)\n",
    "                except:\n",
    "                    for i in range(weight):\n",
    "                        res =  model.fit_predict(X_test)\n",
    "                        res[res == -1] = 1\n",
    "                        res = self.flip_if_inverted(res)\n",
    "                        results.append(res)\n",
    "\n",
    "            results = np.array(results)      \n",
    "            # find majority\n",
    "            results=results.T\n",
    "\n",
    "            final_res = []\n",
    "            for i in list(results):\n",
    "                final_res.append(int(Counter(i).most_common(1)[0][0]))\n",
    "            end_time = time.time()\n",
    "\n",
    "            accuracy, precision, recall, f1_score, fpr, tpr, roc_auc = self.result(Y_test, final_res)\n",
    "\n",
    "            fpr_.append(fpr)\n",
    "            tpr_.append(tpr)\n",
    "\n",
    "            accuracy_.append(accuracy)\n",
    "            precision_.append(precision)\n",
    "            recall_.append(recall)\n",
    "            f1_score_.append(f1_score)\n",
    "            roc_auc_.append(roc_auc)\n",
    "            time_.append(end_time - start_time)  \n",
    "\n",
    "        return np.mean(accuracy_), np.mean(precision_), np.mean(recall_), np.mean(f1_score_), np.mean(time_)\n",
    "    \n",
    "    def optimize_all_voting_parameters(self, weight_permutations, undersample=False, oversample=False):\n",
    "        tuning_res = pd.DataFrame(columns = [\"w1\", \"w2\", 'w3', 'w4', 'w5','w6', \"accuracy\", \"precision\", \"recall\",\\\n",
    "                                             \"f1_score\", \"fpr\", \"tpr\", \"roc_auc\", \"time\"])\n",
    "\n",
    "        for permutation in weight_permutations:\n",
    "            start_time = time.time()\n",
    "            w1_, w2_, w3_, w4_,w5_,w6_ = permutation\n",
    "\n",
    "            accuracy, precision, recall, f1_score, fpr, tpr, roc_auc, time_ = \\\n",
    "                self.weighted_vote_ensamble(weights=list(permutation), undersample=undersample, oversample=oversample)\n",
    "\n",
    "\n",
    "            end_time=time.time()\n",
    "            row = {\"w1\":w1_, \"w2\":w2_, 'w3':w3_,'w4':w4_,'w5':w5_, 'w6':w6_,\"accuracy\":accuracy, \"precision\":precision,\\\n",
    "                   \"recall\":recall, \"f1_score\":f1_score, \"fpr\":fpr, \"tpr\":tpr, \"roc_auc\":roc_auc, 'time':end_time-start_time}\n",
    "            tuning_res = tuning_res.append(row, ignore_index=True)\n",
    "        return tuning_res.sort_values(\"f1_score\", ascending=False)\n",
    "\n",
    "\n",
    "    def stack(self, models, undersample=False, oversample=False):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.X,self.Y, test_size=0.4, random_state=22)\n",
    "\n",
    "        if undersample:\n",
    "            undersampling = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "            X_train, Y_train = undersampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "        if oversample:\n",
    "            oversamping = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "            X_train, Y_train = oversamping.fit_resample(X_train, Y_train)\n",
    "\n",
    "        start_time = time.time()\n",
    "        S_train, S_test = stacking(models,                   \n",
    "                                    X_train, Y_train, X_test,   \n",
    "                                   regression=False, \n",
    "\n",
    "                                    mode='oof_pred_bag', \n",
    "\n",
    "                                   needs_proba=False,\n",
    "\n",
    "                                   save_dir=None, \n",
    "\n",
    "                                   metric=accuracy_score, \n",
    "\n",
    "                                   n_folds=4, \n",
    "\n",
    "                                   stratified=True,\n",
    "\n",
    "                                   shuffle=True,  \n",
    "\n",
    "                                   random_state=0,    \n",
    "\n",
    "                                   verbose=2)\n",
    "\n",
    "        model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1,\n",
    "                              n_estimators=100, max_depth=3)\n",
    "        model = model.fit(S_train, Y_train)\n",
    "\n",
    "        y_pred = model.predict(S_test)\n",
    "\n",
    "        accuracy, precision, recall, f1_score, fpr, tpr, roc_auc = self.result(Y_test, y_pred)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        return accuracy, precision, recall, f1_score, end_time - start_time\n",
    "\n",
    "    def generate_models(self, weights, undersample=False, oversample=False):\n",
    "        df = pd.DataFrame(columns=['model','accuracy', 'precision', 'recall', 'f1 score', 'time'])\n",
    "        for model in all_models:\n",
    "            accuracy, precision, recall, f1_score, time = self.validate_model(model, undersample=undersample, \\\n",
    "                                                                            oversample=oversample)\n",
    "            df = df.append({'model':model,'accuracy': accuracy, 'precision':precision, 'recall':recall, \\\n",
    "                            'f1 score':f1_score, 'time':time}, ignore_index=True)\n",
    "            \n",
    "        #ensemble models\n",
    "#         for i,j in zip([self.unsupervised_models[1:], self.supervised_models, self.all_models[1:]],\\\n",
    "#                             ['unsupervised stacking', 'supervised stacking', 'all model stacking']):\n",
    "#             accuracy, precision, recall, f1_score, time = self.stack(i, \\\n",
    "#                                                                     undersample=undersample, \\\n",
    "#                                                                     oversample=oversample)\n",
    "#             df = df.append({'model':j,'accuracy': accuracy, 'precision':precision, 'recall':recall, \\\n",
    "#                                 'f1 score':f1_score, 'time':time}, ignore_index=True)\n",
    "\n",
    "        for i,j in zip([self.unsupervised_models[1:], self.supervised_models, self.all_models[1:]],\\\n",
    "                            ['unsupervised voting', 'supervised voting', 'all model voting']):\n",
    "            accuracy, precision, recall, f1_score, time = self.weighted_vote_ensamble(models=i, weights=[1,1,1],\\\n",
    "                                                                                     oversample=oversample,\\\n",
    "                                                                                     undersample=undersample)\n",
    "            df = df.append({'model':j,'accuracy': accuracy, 'precision':precision, 'recall':recall, \\\n",
    "                                'f1 score':f1_score, 'time':time}, ignore_index=True)\n",
    "            \n",
    "        for i,j,z in zip([self.unsupervised_models[1:], self.supervised_models, self.all_models[1:], weights],\\\n",
    "                            ['unsupervised weighted voting', 'supervised weighted voting', 'all model weighted voting'],\\\n",
    "                            weights):\n",
    "            accuracy, precision, recall, f1_score, time = self.weighted_vote_ensamble(models=i, weights=z,\\\n",
    "                                                                                     oversample=oversample,\\\n",
    "                                                                                     undersample=undersample)\n",
    "            df = df.append({'model':j,'accuracy': accuracy, 'precision':precision, 'recall':recall, \\\n",
    "                                'f1 score':f1_score, 'time':time}, ignore_index=True)\n",
    "\n",
    "        return df.sort_values(by=\"f1 score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_model = DBSCAN(eps=3, min_samples=2)\n",
    "isolation_forest_model = IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), \\\n",
    "                        max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "kmeans_model = KMeans(n_clusters=2)\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "rf_model = RandomForestClassifier(max_depth=10, random_state=5)\n",
    "\n",
    "all_models = [dbscan_model, isolation_forest_model, kmeans_model, knn_model, svm_model, rf_model]\n",
    "unsupervised_models = [dbscan_model, isolation_forest_model, kmeans_model]\n",
    "supervised_models = [knn_model, svm_model, rf_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmsad = FMSAD(X,Y, supervised_models, unsupervised_models)\n",
    "fmsad.correlation_analysis()\n",
    "selected_feature_names = fmsad.correlation_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 different features selection approaches\n",
    "df1 = X\n",
    "df2 = X[selected_feature_names].copy()\n",
    "df3 = pca_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(StandardScaler(), SVC(gamma='auto'))</td>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.964713</td>\n",
       "      <td>0.968236</td>\n",
       "      <td>0.966078</td>\n",
       "      <td>0.031485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>supervised weighted voting</td>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.964713</td>\n",
       "      <td>0.968236</td>\n",
       "      <td>0.966078</td>\n",
       "      <td>0.199090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>0.963699</td>\n",
       "      <td>0.962400</td>\n",
       "      <td>0.965111</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.152700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>supervised voting</td>\n",
       "      <td>0.963014</td>\n",
       "      <td>0.961252</td>\n",
       "      <td>0.965358</td>\n",
       "      <td>0.962652</td>\n",
       "      <td>0.246604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all model weighted voting</td>\n",
       "      <td>0.956164</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>0.956002</td>\n",
       "      <td>0.955542</td>\n",
       "      <td>0.878958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.943151</td>\n",
       "      <td>0.941690</td>\n",
       "      <td>0.944074</td>\n",
       "      <td>0.942489</td>\n",
       "      <td>0.035912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all model voting</td>\n",
       "      <td>0.708219</td>\n",
       "      <td>0.743639</td>\n",
       "      <td>0.678506</td>\n",
       "      <td>0.673475</td>\n",
       "      <td>0.556486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KMeans(n_clusters=2)</td>\n",
       "      <td>0.552055</td>\n",
       "      <td>0.584593</td>\n",
       "      <td>0.574981</td>\n",
       "      <td>0.545691</td>\n",
       "      <td>0.120523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unsupervised weighted voting</td>\n",
       "      <td>0.552055</td>\n",
       "      <td>0.584593</td>\n",
       "      <td>0.574981</td>\n",
       "      <td>0.545691</td>\n",
       "      <td>0.462887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ExtraTreeRegressor(max_depth=8, max_features=...</td>\n",
       "      <td>0.628767</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.584623</td>\n",
       "      <td>0.542958</td>\n",
       "      <td>0.351893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unsupervised voting</td>\n",
       "      <td>0.628767</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.584623</td>\n",
       "      <td>0.542958</td>\n",
       "      <td>0.432735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DBSCAN(eps=3, min_samples=2)</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.280822</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.030226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  accuracy  precision  \\\n",
       "4               (StandardScaler(), SVC(gamma='auto'))  0.966438   0.964713   \n",
       "10                         supervised weighted voting  0.966438   0.964713   \n",
       "5   (DecisionTreeClassifier(max_depth=10, max_feat...  0.963699   0.962400   \n",
       "7                                   supervised voting  0.963014   0.961252   \n",
       "11                          all model weighted voting  0.956164   0.955284   \n",
       "3                              KNeighborsClassifier()  0.943151   0.941690   \n",
       "8                                    all model voting  0.708219   0.743639   \n",
       "2                                KMeans(n_clusters=2)  0.552055   0.584593   \n",
       "9                        unsupervised weighted voting  0.552055   0.584593   \n",
       "1   (ExtraTreeRegressor(max_depth=8, max_features=...  0.628767   0.680628   \n",
       "6                                 unsupervised voting  0.628767   0.680628   \n",
       "0                        DBSCAN(eps=3, min_samples=2)  0.561644   0.280822   \n",
       "\n",
       "      recall  f1 score      time  \n",
       "4   0.968236  0.966078  0.031485  \n",
       "10  0.968236  0.966078  0.199090  \n",
       "5   0.965111  0.963284  0.152700  \n",
       "7   0.965358  0.962652  0.246604  \n",
       "11  0.956002  0.955542  0.878958  \n",
       "3   0.944074  0.942489  0.035912  \n",
       "8   0.678506  0.673475  0.556486  \n",
       "2   0.574981  0.545691  0.120523  \n",
       "9   0.574981  0.545691  0.462887  \n",
       "1   0.584623  0.542958  0.351893  \n",
       "6   0.584623  0.542958  0.432735  \n",
       "0   0.500000  0.359649  0.030226  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmsad.validate_model(isolation_forest_model)\n",
    "fmsad.generate_models([[0,3,2],[0,3,2],[3,1,1,3,2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
