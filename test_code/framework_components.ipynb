{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "import requests \n",
    "import pickle as pkl \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from scipy import stats\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "\n",
    "#models \n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier  \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28311\n",
      "24553\n",
      "3758\n"
     ]
    }
   ],
   "source": [
    "# create input and output data\n",
    "\n",
    "data = pd.read_csv(\"mts_june_10m_rh.csv\", dtype='float').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "X = data.drop(['cs'], axis=1)\n",
    "Y = data['cs']\n",
    "\n",
    "# data = pd.read_pickle(r'all_metrics_data_3h.pkl')\n",
    "# data = pd.read_pickle(r'all_metrics_data_12h.pkl')\n",
    "\n",
    "# X = data.drop(['time', 'label', \"txn_fail_num\"], axis=1)\n",
    "# Y = data.label\n",
    "print(len(data))\n",
    "print(len(data[data.cs == 1]))\n",
    "print(len(data[data.cs == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components = 0.95)\n",
    "pca_df = pca.fit_transform(scaled_df)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_txn_falure = {}\n",
    "\n",
    "for label in X.columns:\n",
    "    r,p = stats.pearsonr(X[label],Y)\n",
    "    correlation_txn_falure[label] = (r,p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_falure_correlation = pd.DataFrame.from_dict(correlation_txn_falure, orient='index').rename(columns={0:'r', 1:'p-value'}).sort_values('r', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(txn_falure_correlation, cmap='GnBu', square=True, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlations = data.corr().dropna(axis=1, how='all').T.dropna(axis=1, how='all').T\n",
    "# heatmap\n",
    "\n",
    "matrix = np.triu(correlations)\n",
    "\n",
    "plt.figure(figsize=(11,9))\n",
    "sns.heatmap(correlations, cmap='GnBu', square=True, annot=False, linewidths=.5, mask=matrix)\n",
    "#plt.savefig('xx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <td>0.040725</td>\n",
       "      <td>7.134239e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc</th>\n",
       "      <td>0.027616</td>\n",
       "      <td>3.362653e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rn</th>\n",
       "      <td>-0.020392</td>\n",
       "      <td>6.007836e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rh</th>\n",
       "      <td>-0.049427</td>\n",
       "      <td>8.699338e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt</th>\n",
       "      <td>-0.073715</td>\n",
       "      <td>2.045137e-35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           r       p-value\n",
       "ts  0.040725  7.134239e-12\n",
       "bc  0.027616  3.362653e-06\n",
       "rn -0.020392  6.007836e-04\n",
       "rh -0.049427  8.699338e-17\n",
       "tt -0.073715  2.045137e-35"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index = list(txn_falure_correlation.index)\n",
    "\n",
    "# drop Nan\n",
    "txn_falure_correlation = txn_falure_correlation.dropna(axis='rows')\n",
    "txn_falure_correlation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = txn_falure_correlation[np.abs(txn_falure_correlation.r) >0.5]\n",
    "selected_features = selected_features[selected_features['p-value'] < 0.05]\n",
    "\n",
    "selected_features_names = selected_features.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def evaluate(y_real, y_pred):\n",
    "    from sklearn import metrics\n",
    "    accuracy = accuracy_score(y_real,y_pred)\n",
    "    precision = precision_score(y_real, y_pred, average='macro')\n",
    "    recall = metrics.recall_score(y_real, y_pred, average='macro')\n",
    "    f1_score = metrics.f1_score(y_real, y_pred, average='macro') \n",
    "    \n",
    "    # AUC curve\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_real, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return accuracy, precision, recall, f1_score, fpr, tpr, roc_auc\n",
    "\n",
    "# since boolean predictions may be wrong way around\n",
    "def result(y_real, y_pred):\n",
    "    from sklearn import metrics\n",
    "    if  metrics.f1_score(y_real, y_pred, average='macro') >  metrics.f1_score(y_real, [not y for y in y_pred], average='macro'):\n",
    "        return evaluate(y_real, y_pred)\n",
    "    else:\n",
    "        return evaluate(y_real, [not y for y in y_pred])\n",
    "\n",
    "def show_res(res):\n",
    "    accuracy, precision, recall, f1_score,fpr, tpr, roc_auc, time = res\n",
    "    print(\"Accuracy\", accuracy)\n",
    "    print(\"Precision\", precision)\n",
    "    print(\"Recall\", recall)\n",
    "    print(\"F1 Score\", f1_score)\n",
    "    print(\"Time\", time)\n",
    "    \n",
    "def flip_if_inverted(Y_pred):\n",
    "    Y_pred = np.array([0 if i != 1 else 1 for i in Y_pred ])\n",
    "    if len(Y_pred[Y_pred == 1]) < len(Y_pred[Y_pred == 0]):\n",
    "        \n",
    "        return [not elem for elem in Y_pred]\n",
    "    else:\n",
    "        return Y_pred\n",
    "    \n",
    "def validate_model(model, X, Y,undersample=False, oversample=False, flip=True):\n",
    "    accuracy_, precision_, recall_, f1_score_,fpr_, tpr_, roc_auc_, time_ = [],[],[],[],[], [],[],[]\n",
    "\n",
    "    shuffle_split = StratifiedShuffleSplit(n_splits=5, test_size=0.4, random_state=0)\n",
    "    for train_index, test_index in shuffle_split.split(X,Y):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if type(X) == pd.DataFrame:\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        else:\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        if undersample:\n",
    "            undersampling = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "            X_train, Y_train = undersampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "        if oversample:\n",
    "            oversampling = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "            X_train, Y_train = oversampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "        fitted_model = model.fit(X_train, Y_train)\n",
    "        try:\n",
    "            y_pred = fitted_model.predict(X_test)\n",
    "        except:\n",
    "            y_pred = fitted_model.fit_predict(X_test)\n",
    "        ####\n",
    "        #### IS THIS ALLOWED?\n",
    "        ####\n",
    "        ####\n",
    "        if flip:\n",
    "            y_pred = flip_if_inverted(y_pred)\n",
    "        \n",
    "        accuracy, precision, recall, f1_score, fpr, tpr, roc_auc = result(Y_test, y_pred)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        fpr_.append(fpr)\n",
    "        tpr_.append(tpr)\n",
    "        \n",
    "        accuracy_.append(accuracy)\n",
    "        precision_.append(precision)\n",
    "        recall_.append(recall)\n",
    "        f1_score_.append(f1_score)\n",
    "        roc_auc_.append(roc_auc)\n",
    "        time_.append(end_time - start_time)  \n",
    "    return np.mean(accuracy_), np.mean(precision_), np.mean(recall_), np.mean(f1_score_), np.mean(time_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_model = DBSCAN(eps=3, min_samples=2)\n",
    "isolation_forest_model = IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), \\\n",
    "                        max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "kmeans_model = KMeans(n_clusters=2)\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "rf_model = RandomForestClassifier(max_depth=10, random_state=5)\n",
    "\n",
    "all_models = [dbscan_model, isolation_forest_model, kmeans_model, knn_model, svm_model, rf_model]\n",
    "unsupervised_models = [dbscan_model, isolation_forest_model, kmeans_model]\n",
    "supervised_models = [knn_model, svm_model, rf_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All metrics\n",
      "(0.9748262548262548, 0.963320369314889, 0.9759667024704617, 0.9692973874232719, 0.777504301071167)\n",
      "(0.972972972972973, 0.9617317910570131, 0.9726699991737586, 0.9669658044046778, 0.4693434715270996)\n"
     ]
    }
   ],
   "source": [
    "supervised_voting_model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[1,1,1])\n",
    "\n",
    "\n",
    "print(\"All metrics\")\n",
    "print(validate_model(supervised_voting_model, X,Y))\n",
    "print(validate_model(supervised_voting_model, pca_df,Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_voting_parameters(X,Y, w1, w2,w3):\n",
    "    tuning_res = pd.DataFrame(columns = [\"w1\", \"w2\", 'w3', \"accuracy\", \"precision\", \"recall\",\\\n",
    "                                         \"f1_score\", \"fpr\", \"tpr\", \"roc_auc\", \"time\"])\n",
    "\n",
    "    for w1_, w2_, w3_ in itertools.product(*[w1, w2,w3]):\n",
    "        dbscan_clf = DBSCAN(eps=3, min_samples=2)\n",
    "        if_clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), \\\n",
    "                                max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "        kmeans_clf = KMeans(n_clusters=2)\n",
    "        KNN_clf = KNeighborsClassifier(n_neighbors=2)\n",
    "        svm_clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "        rf_clf = RandomForestClassifier(max_depth=10, random_state=5)      \n",
    "\n",
    "        # dbscan, IF and kmeans does not work since it is no classifier\n",
    "        model = VotingClassifier(estimators=[\n",
    "                ('knn', KNN_clf), \\\n",
    "                ('svm', svm_clf),('random forest', rf_clf)], voting='hard', weights=[w1_, w2_, w3_])\n",
    "        validate_model(model, X,Y)\n",
    "\n",
    "        accuracy, precision, recall, f1_score, fpr, tpr, roc_auc, time = \\\n",
    "                validate_model(model, X, Y)\n",
    "        \n",
    "        row = {\"w1\":w1_, \"w2\":w2_, 'w3':w3_,\"accuracy\":accuracy, \"precision\":precision,\\\n",
    "               \"recall\":recall, \"f1_score\":f1_score, \"fpr\":fpr, \"tpr\":tpr, \"roc_auc\":roc_auc}\n",
    "        tuning_res = tuning_res.append(row, ignore_index=True)\n",
    "    return tuning_res.sort_values(\"f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_vote_ensamble(X,Y, models, weights=[1,1,1,1,1,1], undersample=False, oversample=False):\n",
    "    accuracy_, precision_, recall_, f1_score_,fpr_, tpr_, roc_auc_, time_ = [],[],[],[],[], [],[],[]\n",
    "\n",
    "    shuffle_split = StratifiedShuffleSplit(n_splits=5, test_size=0.4, random_state=0)\n",
    "    for train_index, test_index in shuffle_split.split(X,Y):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if type(X) == pd.DataFrame:\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        else:\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        if undersample:\n",
    "            undersampling = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "            X_train, Y_train = undersampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "        if oversample:\n",
    "            oversampling = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "            X_train, Y_train = oversampling.fit_resample(X_train, Y_train)\n",
    "\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = []\n",
    "        for model, weight in zip(models, weights):\n",
    "            try:\n",
    "                model.fit(X_train, Y_train)\n",
    "                for i in range(weight):\n",
    "                    res = model.predict(X_test)\n",
    "                    res = flip_if_inverted(res)\n",
    "                    results.append(res)\n",
    "            except:\n",
    "                for i in range(weight):\n",
    "                    res =  model.fit_predict(X_test)\n",
    "                    res[res == -1] = 1\n",
    "                    res = flip_if_inverted(res)\n",
    "                    results.append(res)\n",
    "\n",
    "        results = np.array(results)      \n",
    "        # find majority\n",
    "        results=results.T\n",
    "        \n",
    "        final_res = []\n",
    "        for i in list(results):\n",
    "            final_res.append(int(Counter(i).most_common(1)[0][0]))\n",
    "        end_time = time.time()\n",
    "        \n",
    "        accuracy, precision, recall, f1_score, fpr, tpr, roc_auc = result(Y_test, final_res)\n",
    "        \n",
    "        fpr_.append(fpr)\n",
    "        tpr_.append(tpr)\n",
    "        \n",
    "        accuracy_.append(accuracy)\n",
    "        precision_.append(precision)\n",
    "        recall_.append(recall)\n",
    "        f1_score_.append(f1_score)\n",
    "        roc_auc_.append(roc_auc)\n",
    "        time_.append(end_time - start_time)  \n",
    "        \n",
    "    return np.mean(accuracy_), np.mean(precision_), np.mean(recall_), np.mean(f1_score_), np.mean(time_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9748262548262548,\n",
       " 0.963320369314889,\n",
       " 0.9759667024704617,\n",
       " 0.9692973874232719,\n",
       " 0.7491046905517578)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_vote_ensamble(X,Y, models = supervised_models, weights=[1,1,1], undersample=False, oversample=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7045559845559846,\n",
       " 0.49044830557724267,\n",
       " 0.4990456911509543,\n",
       " 0.43909033851436413,\n",
       " 2.300420045852661)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_vote_ensamble(X,Y, models = unsupervised_models, weights=[1,1,1], undersample=False, oversample=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_all_voting_parameters(X,Y, weight_permutations, undersample=False, oversample=False):\n",
    "    tuning_res = pd.DataFrame(columns = [\"w1\", \"w2\", 'w3', 'w4', 'w5','w6', \"accuracy\", \"precision\", \"recall\",\\\n",
    "                                         \"f1_score\", \"fpr\", \"tpr\", \"roc_auc\", \"time\"])\n",
    "   \n",
    "    for permutation in weight_permutations:\n",
    "        start_time = time.time()\n",
    "        w1_, w2_, w3_, w4_,w5_,w6_ = permutation\n",
    "        \n",
    "        accuracy, precision, recall, f1_score, fpr, tpr, roc_auc, time_ = \\\n",
    "            weighted_vote_ensamble(X,Y, weights=list(permutation), undersample=undersample, oversample=oversample)\n",
    "\n",
    "\n",
    "        end_time=time.time()\n",
    "        row = {\"w1\":w1_, \"w2\":w2_, 'w3':w3_,'w4':w4_,'w5':w5_, 'w6':w6_,\"accuracy\":accuracy, \"precision\":precision,\\\n",
    "               \"recall\":recall, \"f1_score\":f1_score, \"fpr\":fpr, \"tpr\":tpr, \"roc_auc\":roc_auc, 'time':end_time-start_time}\n",
    "        tuning_res = tuning_res.append(row, ignore_index=True)\n",
    "    return tuning_res.sort_values(\"f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def stack(X,Y, models, undersample=False, oversample=False):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.4, random_state=22)\n",
    "\n",
    "    if undersample:\n",
    "        undersampling = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "        X_train, Y_train = undersampling.fit_resample(X_train, Y_train)\n",
    "            \n",
    "    if oversample:\n",
    "        oversamping = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "        X_train, Y_train = oversamping.fit_resample(X_train, Y_train)\n",
    "            \n",
    "    start_time = time.time()\n",
    "    S_train, S_test = stacking(models,                   \n",
    "                                X_train, Y_train, X_test,   \n",
    "                               regression=False, \n",
    "\n",
    "                                mode='oof_pred_bag', \n",
    "\n",
    "                               needs_proba=False,\n",
    "\n",
    "                               save_dir=None, \n",
    "\n",
    "                               metric=accuracy_score, \n",
    "\n",
    "                               n_folds=4, \n",
    "\n",
    "                               stratified=True,\n",
    "\n",
    "                               shuffle=True,  \n",
    "\n",
    "                               random_state=0,    \n",
    "\n",
    "                               verbose=2)\n",
    "\n",
    "    model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1,\n",
    "                          n_estimators=100, max_depth=3)\n",
    "    model = model.fit(S_train, Y_train)\n",
    "\n",
    "    y_pred = model.predict(S_test)\n",
    "    \n",
    "    accuracy, precision, recall, f1_score, fpr, tpr, roc_auc = result(Y_test, y_pred)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score, end_time - start_time\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(x1, x2, x3, method):\n",
    "    if x1:\n",
    "        accuracy1, precision1, recall1, f1_score1, time1 = x1\n",
    "        print(f\"{method} & {accuracy1:.2f} &{precision1:.2f}& {recall1:.2f} & {f1_score1:.2f} & {time1:.2f} &\",end=\"\")\n",
    "    if x2:\n",
    "        accuracy2, precision2, recall2, f1_score2, time2 = x2\n",
    "        print(f\"{accuracy2:.2f} &{precision2:.2f}& {recall2:.2f} &{f1_score2:.2f}& {time2:.2f} & \",end=\"\")\n",
    "    if x3:\n",
    "        accuracy3, precision3, recall3, f1_score3, time3 = x3\n",
    "    print(f\"{accuracy3:.2f} &{precision3:.2f}& {recall3:.2f} & {f1_score3:.2f} & {time3:.2f} \\\\\\\\ \\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = X\n",
    "df2 = X[selected_features_names].copy()\n",
    "df3 = pca_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF & 0.79 &0.53& 0.52 & 0.52 & 0.84 &0.79 &0.54& 0.53 & 0.53 & 0.82 \\\\ \\hline\n",
      "DBSCAN & 0.87 &0.43& 0.50 & 0.46 & 0.18 &0.87 &0.43& 0.50 & 0.46 & 3.54 \\\\ \\hline\n",
      "K-means & 0.87 &0.48& 0.50 & 0.46 & 1.34 &0.54 &0.49& 0.47 & 0.43 & 1.57 \\\\ \\hline\n",
      "KNN & 0.87 &0.70& 0.61 & 0.64 & 0.32 &0.90 &0.79& 0.71 & 0.74 & 0.29 \\\\ \\hline\n",
      "SVM & 0.87 &0.75& 0.50 & 0.47 & 9.24 &0.87 &0.43& 0.50 & 0.46 & 5.36 \\\\ \\hline\n",
      "RF & 0.93 &0.88& 0.79 & 0.82 & 1.44 &0.89 &0.86& 0.59 & 0.61 & 1.30 \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "x1 = validate_model(isolation_forest_model, df1,Y)\n",
    "# x2 = validate_model(isolation_forest_model, df2,Y)\n",
    "x2= None\n",
    "x3 = validate_model(isolation_forest_model, df3,Y)\n",
    "table(x1, x2, x3, \"IF\")\n",
    "\n",
    "x1 = validate_model(dbscan_model, df1,Y)\n",
    "# x2 = validate_model(dbscan_model, df2,Y)\n",
    "x3 = validate_model(dbscan_model, df3,Y)\n",
    "table(x1, x2, x3, \"DBSCAN\")\n",
    "\n",
    "x1 = validate_model(kmeans_model, df1,Y)\n",
    "# x2 = validate_model(kmeans_model, df2,Y)\n",
    "x3 = validate_model(kmeans_model, df3,Y)\n",
    "table(x1, x2, x3, \"K-means\")\n",
    "\n",
    "x1 = validate_model(knn_model, df1,Y)\n",
    "# x2 = validate_model(knn_model, df2,Y)\n",
    "x3 = validate_model(knn_model, df3,Y)\n",
    "table(x1, x2, x3, \"KNN\")\n",
    "\n",
    "x1 = validate_model(svm_model, df1,Y)\n",
    "# x2 = validate_model(svm_model, df2,Y)\n",
    "x3 = validate_model(svm_model, df3,Y)\n",
    "table(x1, x2, x3, \"SVM\")\n",
    "\n",
    "x1 = validate_model(rf_model, df1,Y)\n",
    "# x2 = validate_model(rf_model, df2,Y)\n",
    "x3 = validate_model(rf_model, df3,Y)\n",
    "table(x1, x2, x3, \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ee96680d3bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# x2 = validate_model(isolation_forest_model, df1,Y, oversample=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misolation_forest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbscan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x2' is not defined"
     ]
    }
   ],
   "source": [
    "x1 = validate_model(isolation_forest_model, df1,Y, oversample=True)\n",
    "# x2 = validate_model(isolation_forest_model, df1,Y, oversample=True)\n",
    "x3 = validate_model(isolation_forest_model, df1,Y, oversample=True)\n",
    "table(x1, x2, x3, \"IF\")\n",
    "\n",
    "x1 = validate_model(dbscan_model, df1,Y, oversample=True)\n",
    "# x2 = validate_model(dbscan_model, df2,Y, oversample=True)\n",
    "x3 = validate_model(dbscan_model, df3,Y, oversample=True)\n",
    "table(x1, x2, x3, \"DBSCAN\")\n",
    "\n",
    "x1 = validate_model(kmeans_model, df1,Y, oversample=True)\n",
    "# x2 = validate_model(kmeans_model, df2,Y, oversample=True)\n",
    "x3 = validate_model(kmeans_model, df3,Y, oversample=True)\n",
    "table(x1, x2, x3, \"K-means\")\n",
    "\n",
    "x1 = validate_model(knn_model, df1,Y, oversample=True)\n",
    "# x2 = validate_model(knn_model, df2,Y, oversample=True)\n",
    "x3 = validate_model(knn_model, df3,Y, oversample=True)\n",
    "table(x1, x2, x3, \"KNN\")\n",
    "\n",
    "x1 = validate_model(svm_model, df1,Y, oversample=True)\n",
    "# x2 = validate_model(svm_model, df2,Y, oversample=True)\n",
    "x3 = validate_model(svm_model, df3,Y, oversample=True)\n",
    "table(x1, x2, x3, \"SVM\")\n",
    "\n",
    "x1 = validate_model(rf_model, df1,Y, oversample=True)\n",
    "# x2 = validate_model(rf_model, df2,Y, oversample=True)\n",
    "x3 = validate_model(rf_model, df3,Y, oversample=True)\n",
    "table(x1, x2, x3, \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = validate_model(isolation_forest_model, df1,Y, undersample=True)\n",
    "# x2 = validate_model(isolation_forest_model, df1,Y, undersample=True)\n",
    "x3 = validate_model(isolation_forest_model, df1,Y, undersample=True)\n",
    "table(x1, x2, x3, \"IF\")\n",
    "\n",
    "x1 = validate_model(dbscan_model, df1,Y, undersample=True)\n",
    "# x2 = validate_model(dbscan_model, df2,Y, undersample=True)\n",
    "x3 = validate_model(dbscan_model, df3,Y, undersample=True)\n",
    "table(x1, x2, x3, \"DBSCAN\")\n",
    "\n",
    "x1 = validate_model(kmeans_model, df1,Y, undersample=True)\n",
    "# x2 = validate_model(kmeans_model, df2,Y, undersample=True)\n",
    "x3 = validate_model(kmeans_model, df3,Y, undersample=True)\n",
    "table(x1, x2, x3, \"K-means\")\n",
    "\n",
    "x1 = validate_model(knn_model, df1,Y, undersample=True)\n",
    "# x2 = validate_model(knn_model, df2,Y, undersample=True)\n",
    "x3 = validate_model(knn_model, df3,Y, undersample=True)\n",
    "table(x1, x2, x3, \"KNN\")\n",
    "\n",
    "x1 = validate_model(svm_model, df1,Y, undersample=True)\n",
    "# x2 = validate_model(svm_model, df2,Y, undersample=True)\n",
    "x3 = validate_model(svm_model, df3,Y, undersample=True)\n",
    "table(x1, x2, x3, \"SVM\")\n",
    "\n",
    "x1 = validate_model(rf_model, df1,Y, undersample=True)\n",
    "# x2 = validate_model(rf_model, df2,Y, undersample=True)\n",
    "x3 = validate_model(rf_model, df3,Y, undersample=True)\n",
    "table(x1, x2, x3, \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [IsolationForest]\n",
      "    fold  0:  [0.76595244]\n",
      "    fold  1:  [0.76712974]\n",
      "    fold  2:  [0.77013660]\n",
      "    fold  3:  [0.76895902]\n",
      "    ----\n",
      "    MEAN:     [0.76804445] + [0.00161452]\n",
      "    FULL:     [0.76804427]\n",
      "\n",
      "model  1:     [KMeans]\n",
      "    fold  0:  [0.13656699]\n",
      "    fold  1:  [0.13397692]\n",
      "    fold  2:  [0.13495054]\n",
      "    fold  3:  [0.13659915]\n",
      "    ----\n",
      "    MEAN:     [0.13552340] + [0.00111423]\n",
      "    FULL:     [0.13552337]\n",
      "\n",
      "[22:09:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [IsolationForest]\n",
      "    fold  0:  [0.77584177]\n",
      "    fold  1:  [0.76336237]\n",
      "    fold  2:  [0.76707489]\n",
      "    fold  3:  [0.77131418]\n",
      "    ----\n",
      "    MEAN:     [0.76939830] + [0.00466421]\n",
      "    FULL:     [0.76939833]\n",
      "\n",
      "model  1:     [KMeans]\n",
      "    fold  0:  [0.53943960]\n",
      "    fold  1:  [0.46574052]\n",
      "    fold  2:  [0.47103156]\n",
      "    fold  3:  [0.45831371]\n",
      "    ----\n",
      "    MEAN:     [0.48363135] + [0.03253606]\n",
      "    FULL:     [0.48363358]\n",
      "\n",
      "[22:09:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Unsupervised stacking & 0.87 &0.43& 0.50 & 0.46 & 10.30 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.87 &0.43& 0.50 & 0.46 & 11.57 \\\\ \\hline\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.87002590]\n",
      "    fold  1:  [0.86625854]\n",
      "    fold  2:  [0.86764013]\n",
      "    fold  3:  [0.87588318]\n",
      "    ----\n",
      "    MEAN:     [0.86995194] + [0.00368004]\n",
      "    FULL:     [0.86995172]\n",
      "\n",
      "model  1:     [Pipeline]\n",
      "    fold  0:  [0.86837768]\n",
      "    fold  1:  [0.86837768]\n",
      "    fold  2:  [0.86905323]\n",
      "    fold  3:  [0.86787565]\n",
      "    ----\n",
      "    MEAN:     [0.86842106] + [0.00041859]\n",
      "    FULL:     [0.86842105]\n",
      "\n",
      "model  2:     [RandomForestClassifier]\n",
      "    fold  0:  [0.93077466]\n",
      "    fold  1:  [0.93195197]\n",
      "    fold  2:  [0.92251531]\n",
      "    fold  3:  [0.92934527]\n",
      "    ----\n",
      "    MEAN:     [0.92864680] + [0.00365838]\n",
      "    FULL:     [0.92864712]\n",
      "\n",
      "[22:09:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.89710384]\n",
      "    fold  1:  [0.88721450]\n",
      "    fold  2:  [0.88742346]\n",
      "    fold  3:  [0.89943476]\n",
      "    ----\n",
      "    MEAN:     [0.89279414] + [0.00553733]\n",
      "    FULL:     [0.89279407]\n",
      "\n",
      "model  1:     [Pipeline]\n",
      "    fold  0:  [0.86837768]\n",
      "    fold  1:  [0.86814222]\n",
      "    fold  2:  [0.86834668]\n",
      "    fold  3:  [0.86834668]\n",
      "    ----\n",
      "    MEAN:     [0.86830331] + [0.00009387]\n",
      "    FULL:     [0.86830331]\n",
      "\n",
      "model  2:     [RandomForestClassifier]\n",
      "    fold  0:  [0.88862727]\n",
      "    fold  1:  [0.88203438]\n",
      "    fold  2:  [0.88530382]\n",
      "    fold  3:  [0.89048516]\n",
      "    ----\n",
      "    MEAN:     [0.88661266] + [0.00322989]\n",
      "    FULL:     [0.88661250]\n",
      "\n",
      "[22:10:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Supervised stacking & 0.93 &0.88& 0.79 & 0.83 & 32.53 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.89 &0.78& 0.72 & 0.74 & 25.98 \\\\ \\hline\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [5]\n",
      "\n",
      "model  0:     [IsolationForest]\n",
      "    fold  0:  [0.76595244]\n",
      "    fold  1:  [0.76712974]\n",
      "    fold  2:  [0.77013660]\n",
      "    fold  3:  [0.76895902]\n",
      "    ----\n",
      "    MEAN:     [0.76804445] + [0.00161452]\n",
      "    FULL:     [0.76804427]\n",
      "\n",
      "model  1:     [KMeans]\n",
      "    fold  0:  [0.13656699]\n",
      "    fold  1:  [0.13397692]\n",
      "    fold  2:  [0.13495054]\n",
      "    fold  3:  [0.13659915]\n",
      "    ----\n",
      "    MEAN:     [0.13552340] + [0.00111423]\n",
      "    FULL:     [0.13552337]\n",
      "\n",
      "model  2:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.87002590]\n",
      "    fold  1:  [0.86625854]\n",
      "    fold  2:  [0.86764013]\n",
      "    fold  3:  [0.87588318]\n",
      "    ----\n",
      "    MEAN:     [0.86995194] + [0.00368004]\n",
      "    FULL:     [0.86995172]\n",
      "\n",
      "model  3:     [Pipeline]\n",
      "    fold  0:  [0.86837768]\n",
      "    fold  1:  [0.86837768]\n",
      "    fold  2:  [0.86905323]\n",
      "    fold  3:  [0.86787565]\n",
      "    ----\n",
      "    MEAN:     [0.86842106] + [0.00041859]\n",
      "    FULL:     [0.86842105]\n",
      "\n",
      "model  4:     [RandomForestClassifier]\n",
      "    fold  0:  [0.93077466]\n",
      "    fold  1:  [0.93195197]\n",
      "    fold  2:  [0.92251531]\n",
      "    fold  3:  [0.92934527]\n",
      "    ----\n",
      "    MEAN:     [0.92864680] + [0.00365838]\n",
      "    FULL:     [0.92864712]\n",
      "\n",
      "[22:11:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [5]\n",
      "\n",
      "model  0:     [IsolationForest]\n",
      "    fold  0:  [0.77584177]\n",
      "    fold  1:  [0.76336237]\n",
      "    fold  2:  [0.76707489]\n",
      "    fold  3:  [0.77131418]\n",
      "    ----\n",
      "    MEAN:     [0.76939830] + [0.00466421]\n",
      "    FULL:     [0.76939833]\n",
      "\n",
      "model  1:     [KMeans]\n",
      "    fold  0:  [0.46244408]\n",
      "    fold  1:  [0.53425948]\n",
      "    fold  2:  [0.47432878]\n",
      "    fold  3:  [0.45972680]\n",
      "    ----\n",
      "    MEAN:     [0.48268978] + [0.03027593]\n",
      "    FULL:     [0.48269163]\n",
      "\n",
      "model  2:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.89710384]\n",
      "    fold  1:  [0.88721450]\n",
      "    fold  2:  [0.88742346]\n",
      "    fold  3:  [0.89943476]\n",
      "    ----\n",
      "    MEAN:     [0.89279414] + [0.00553733]\n",
      "    FULL:     [0.89279407]\n",
      "\n",
      "model  3:     [Pipeline]\n",
      "    fold  0:  [0.86837768]\n",
      "    fold  1:  [0.86814222]\n",
      "    fold  2:  [0.86834668]\n",
      "    fold  3:  [0.86834668]\n",
      "    ----\n",
      "    MEAN:     [0.86830331] + [0.00009387]\n",
      "    FULL:     [0.86830331]\n",
      "\n",
      "model  4:     [RandomForestClassifier]\n",
      "    fold  0:  [0.88862727]\n",
      "    fold  1:  [0.88203438]\n",
      "    fold  2:  [0.88530382]\n",
      "    fold  3:  [0.89048516]\n",
      "    ----\n",
      "    MEAN:     [0.88661266] + [0.00322989]\n",
      "    FULL:     [0.88661250]\n",
      "\n",
      "[22:11:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "All model stacking & 0.93 &0.88& 0.79 & 0.83 & 42.83 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.89 &0.79& 0.71 & 0.74 & 35.09 \\\\ \\hline\n",
      "Supervised majority voting & 0.89 &0.89& 0.62 & 0.66 & 10.77 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.89 &0.87& 0.58 & 0.61 & 8.05 \\\\ \\hline\n",
      "Supervised weighted voting & 0.87 &0.75& 0.50 & 0.47 & 10.54 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.87 &0.43& 0.50 & 0.46 & 7.59 \\\\ \\hline\n",
      "Unsupervised majority voting & 0.87 &0.53& 0.50 & 0.47 & 2.37 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.83 &0.51& 0.50 & 0.50 & 6.25 \\\\ \\hline\n",
      "Unsupervised weighted voting & 0.79 &0.53& 0.52 & 0.52 & 2.86 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.79 &0.54& 0.53 & 0.53 & 6.20 \\\\ \\hline\n",
      "all models majority voting & 0.87 &0.53& 0.50 & 0.46 & 12.01 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.87 &0.77& 0.50 & 0.47 & 13.99 \\\\ \\hline\n",
      "all models weighted voting & 0.87 &0.53& 0.50 & 0.46 & 16.55 &0.93 &0.93& 0.88 &0.90& 3.15 & 0.87 &0.77& 0.50 & 0.47 & 19.01 \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "x1 = stack(df1,Y, unsupervised_models[1:], undersample=False, oversample=False)\n",
    "# x2 = stack(df2,Y, unsupervised_models[1:], undersample=False, oversample=False)\n",
    "x3 = stack(df3,Y, unsupervised_models[1:], undersample=False, oversample=False)\n",
    "\n",
    "table(x1, x2, x3, \"Unsupervised stacking\")\n",
    "\n",
    "x1 = stack(df1,Y, supervised_models, undersample=False, oversample=False)\n",
    "# x2 = stack(df2,Y, supervised_models, undersample=False, oversample=False)\n",
    "x3 = stack(df3,Y, supervised_models, undersample=False, oversample=False)\n",
    "\n",
    "table(x1, x2, x3, \"Supervised stacking\")\n",
    "\n",
    "x1 = stack(df1,Y, all_models[1:], undersample=False, oversample=False)\n",
    "# x2 = stack(df2,Y, all_models[1:], undersample=False, oversample=False)\n",
    "x3 = stack(df3,Y, all_models[1:], undersample=False, oversample=False)\n",
    "\n",
    "table(x1, x2, x3, \"All model stacking\")\n",
    "\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[1,1,1])\n",
    "\n",
    "# voting classifier\n",
    "x1 = validate_model(model, df1,Y)\n",
    "# x2 = validate_model(model, df2,Y)\n",
    "x3 = validate_model(model, df3,Y)\n",
    "table(x1, x2, x3, \"Supervised majority voting\")\n",
    "\n",
    "# voting classifier\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[0,3,2])\n",
    "x1 = validate_model(model, df1,Y)\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[2,0,3])\n",
    "# x2 = validate_model(model, df2,Y)\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[0,3,2])\n",
    "x3 = validate_model(model, df3,Y)\n",
    "table(x1, x2, x3, \"Supervised weighted voting\")\n",
    "\n",
    "\n",
    "x1 = weighted_vote_ensamble(df1,Y, models=unsupervised_models, weights=[1,1,1])\n",
    "# x2 = weighted_vote_ensamble(df2,Y, models=unsupervised_models, weights=[1,1,1])\n",
    "x3 = weighted_vote_ensamble(df3,Y, models=unsupervised_models, weights=[1,1,1])\n",
    "table(x1, x2, x3, \"Unsupervised majority voting\")\n",
    "\n",
    "# voting using all classifiers\n",
    "x1 = weighted_vote_ensamble(df1,Y, models=all_models, weights=[0,3,2])\n",
    "# x2 = weighted_vote_ensamble(df2,Y, models=all_models, weights=[0,3,2])\n",
    "x3 = weighted_vote_ensamble(df3,Y, models=all_models, weights=[0,3,2])\n",
    "table(x1, x2, x3, \"Unsupervised weighted voting\")\n",
    "\n",
    "x1 = weighted_vote_ensamble(df1,Y, models=all_models, weights=[1,1,1,1,1,1])\n",
    "# x2 = weighted_vote_ensamble(df2,Y, models=all_models, weights=[1,1,1,1,1,1])\n",
    "x3 = weighted_vote_ensamble(df3,Y, models=all_models, weights=[1,1,1,1,1,1])\n",
    "table(x1, x2, x3, \"all models majority voting\")\n",
    "\n",
    "x1 = weighted_vote_ensamble(df1,Y, models=all_models, weights=[3,1,1,3,2,2])\n",
    "# x2 = weighted_vote_ensamble(df2,Y, models=all_models, weights=[3,1,1,3,2,2])\n",
    "x3 = weighted_vote_ensamble(df3,Y, models=all_models, weights=[3,1,1,3,2,2])\n",
    "table(x1, x2, x3, \"all models weighted voting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [IsolationForest]\n",
      "    fold  0:  [0.43823729]\n",
      "    fold  1:  [0.44284746]\n",
      "    fold  2:  [0.44399241]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d3c662349f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsupervised_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsupervised_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsupervised_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unsupervised stacking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-59d9771264ba>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(X, Y, models, undersample, oversample)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                verbose=2)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/vecstack/core.py\u001b[0m in \u001b[0;36mstacking\u001b[0;34m(models, X_train, y_train, X_test, sample_weight, regression, transform_target, transform_pred, mode, needs_proba, save_dir, metric, n_folds, stratified, shuffle, random_state, verbose)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;31m# Fit 1-st level model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'pred_bag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oof'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oof_pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oof_pred_bag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0;31m# Predict out-of-fold part of train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/vecstack/core.py\u001b[0m in \u001b[0;36mmodel_action\u001b[0;34m(model, X_train, y_train, X_test, sample_weight, action, transform)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'predict'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    278\u001b[0m         super()._fit(X, y, max_samples,\n\u001b[1;32m    279\u001b[0m                      \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontamination\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 381\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x1 = stack(df1,Y, unsupervised_models[1:], oversample=True)\n",
    "x2 = stack(df2,Y, unsupervised_models[1:], oversample=True)\n",
    "x3 = stack(df3,Y, unsupervised_models[1:], oversample=True)\n",
    "\n",
    "table(x1, x2, x3, \"Unsupervised stacking\")\n",
    "\n",
    "x1 = stack(df1,Y, supervised_models, oversample=True)\n",
    "x2 = stack(df2,Y, supervised_models, oversample=True)\n",
    "x3 = stack(df3,Y, supervised_models, oversample=True)\n",
    "\n",
    "table(x1, x2, x3, \"Supervised stacking\")\n",
    "\n",
    "x1 = stack(df1,Y, all_models[1:], oversample=True)\n",
    "x2 = stack(df2,Y, all_models[1:], oversample=True)\n",
    "x3 = stack(df3,Y, all_models[1:], oversample=True)\n",
    "\n",
    "table(x1, x2, x3, \"All model stacking\")\n",
    "\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[1,1,1])\n",
    "\n",
    "# voting classifier\n",
    "x1 = validate_model(model, df1,Y, oversample=True)\n",
    "x2 = validate_model(model, df2,Y, oversample=True)\n",
    "x3 = validate_model(model, df3,Y, oversample=True)\n",
    "table(x1, x2, x3, \"Supervised majority voting\")\n",
    "\n",
    "# voting classifier\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[0,3,2])\n",
    "x1 = validate_model(model, df1,Y, oversample=True)\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[2,0,3])\n",
    "x2 = validate_model(model, df2,Y, oversample=True)\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), \\\n",
    "        ('svm', svm_model),('random forest', rf_model)], voting='hard', weights=[0,3,2])\n",
    "x3 = validate_model(model, df3,Y, oversample=True)\n",
    "table(x1, x2, x3, \"Supervised weighted voting\")\n",
    "\n",
    "\n",
    "x1 = weighted_vote_ensamble(df1,Y, models=unsupervised_models, weights=[1,1,1], oversample=True)\n",
    "x2 = weighted_vote_ensamble(df2,Y, models=unsupervised_models, weights=[1,1,1], oversample=True)\n",
    "x3 = weighted_vote_ensamble(df3,Y, models=unsupervised_models, weights=[1,1,1], oversample=True)\n",
    "table(x1, x2, x3, \"Unsupervised majority voting\")\n",
    "\n",
    "# voting using all classifiers\n",
    "x1 = weighted_vote_ensamble(df1,Y, models=all_models, weights=[0,3,2], oversample=True)\n",
    "x2 = weighted_vote_ensamble(df2,Y, models=all_models, weights=[0,3,2], oversample=True)\n",
    "x3 = weighted_vote_ensamble(df3,Y, models=all_models, weights=[0,3,2], oversample=True)\n",
    "table(x1, x2, x3, \"Unsupervised weighted voting\")\n",
    "\n",
    "x1 = weighted_vote_ensamble(df1,Y, models=all_models, weights=[1,1,1,1,1,1], oversample=True)\n",
    "x2 = weighted_vote_ensamble(df2,Y, models=all_models, weights=[1,1,1,1,1,1], oversample=True)\n",
    "x3 = weighted_vote_ensamble(df3,Y, models=all_models, weights=[1,1,1,1,1,1], oversample=True)\n",
    "table(x1, x2, x3, \"all models majority voting\")\n",
    "\n",
    "x1 = weighted_vote_ensamble(df1,Y, models=all_models, weights=[3,1,1,3,2,2], oversample=True)\n",
    "x2 = weighted_vote_ensamble(df2,Y, models=all_models, weights=[3,1,1,3,2,2], oversample=True)\n",
    "x3 = weighted_vote_ensamble(df3,Y, models=all_models, weights=[3,1,1,3,2,2], oversample=True)\n",
    "table(x1, x2, x3, \"all models weighted voting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
